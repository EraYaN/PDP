%!TEX root=../final.tex
%!TEX program = xelatex
%!TEX spellcheck = en_GB
\documentclass[final]{article}
\input{../../.library/preamble.tex}
\input{../../.library/style.tex}
\addbibresource{../../.library/bibliography.bib}
\begin{document}
\section{Improvements}
Many improvements of the processor were attempted. Unfortunately, because of the difficulty of changing the architecture, not all of these attempts succeeded. This section discusses the failed attempts and why they failed, and the successful attempts and their merit.
\subsection{Cache}
\subsection{Pipeline}

\subsection{Branching}
As discussed in \cref{sec:benchprof}, there is room for improvement in the area of branching. In the original implementation of the processor there are four steps/cycles in the branching process:
\begin{enumerate}
\item The memory control presents the branch opcode it fetched
\item Control decodes the opcode and passes the relevant paramaters to bus\_mux who evaluates whether the branch is taken. Meanwhile, the buffer instruction appears at the output of memory control
\item The ALU computes the new PC while the pipeline is paused
\item Memory control fetches the correct instruction while the buffer instruction enters the decode stage
\end{enumerate}
In this process, the buffer instruction refers to an instruction that is executed whether the branch is taken or not. Sometimes the compiler orders the instruction in such a way that this is a useful instruction. If the compiler is unable to find a suitable instruction, a NOP is inserted. Two main weak points are identified:
\begin{enumerate}
\item A cycle is wasted if the buffer instruction is a NOP
\item The pipeline needs to pause for a cycle to calculate the PC
\end{enumerate}
The first point turned out to be hard to improve upon. The first plan of removing all delay slots and forcing the opcode to NOP if a branch was taken as a cheap branch not taken prediction quickly fell flat as the compiler often used the buffer slot for useful instructions that should be executed whether the branch is taken or not. The second point was investigated more thoroughly.

The 

\subsection{Multiplier}
The original multiplier implementation needs 32 cycles to compute the multiplication of two 32 bits input operands. It should be noted that during this operation, the pipeline is stalled. This is not a very efficient in respect to the average amount of Instructions Per Cycle (IPC). The results of the dynamic profiling (see \cref{fig:instruction-count}) show that that multiplication (\texttt{MULT} and \texttt{MULTU}) is used quite often. To improve performance, the goal is set to design a new multiplier that can do the multiplcation in only 1 clock cycle. By using this approach, the pipeline does not have to be stalled when doing multiplication.

There are different approaches for implementing a multiplication algorithm. In general, the options are: basic, high-radix, tree and array multiplication. The original design uses a basic multiplier. This works by having two input registers for the 32 bit operands and one 64 bit output register. Each clock cycle a partial product is calculated, shifted left (depending on the weight) and added to the current value stored in the output register. For executing one multiplication, this sequence has to be repeated 32 times. In therms of area, this is very efficient. However, its performance could be better.

To speed up the computation, the original implementation is replaced by a tree multiplier. Of course, a radix type multiplier would also make the multiplier faster, but it is more suited for a balanced design (optimal cycles/area). The goal here is to get the best performance possible. A full CSA tree multiplier requires a large amount of area, but will give the fastest design. For designing a full CSA tree multiplier two methods exist: Wallace and Dadda trees. According to \cite{townsend}, the Dadda tree is slightly faster in general. So the new multiplier will be a Dadda Tree multiplier.

Designing a Dadda by hand is reasonable for up to two 8-bit operands. To design a 32-bit multiplier, another method should be used. Instead, a Python script was written to build the Dadda tree. The scripts constructs the tree, reduces it using the Dadda algorithm and generates a list of full/half adders and sum/carry signals. The resulting netlist can be mapped to VHDL using a template. The script can be configured to use input operands of any bit size. The reason for doing so is simple: by setting the script to generate a VHDL description of an 8-bit multiplier, its results could still be checked by inspection. If this description is determined valid, scaling it up to 32 bits is done by changing a single line of code. After generating the Dadda Tree, a VHDL testbench was written to verify the logic of the new multiplier.

\subsection{Divider}
%Size = FIFO=14 Slice = 4623
%Size without: FIFO = 14 Slice = 4163
\Cref{fig:instruction-count} shows that very few of the instructions executed in the benchmarks are divisions. This fact initially discouraged attempting to improve the divider. However, after multiple attempts at improving the processor in other areas proved to be unfruitful it was decided to take a second look at the divider anyway. While a small percentage of the instructions are divisions, one single division still takes 32 cycles making the impact on the performance of the processor more significant than \cref{fig:instruction-count} may suggest. 

The original implementation of the division algorithm in the processor is a very simple shift and subtract algorithm. It shifts the divisor to the right attempting to subtract it from the dividend along the way. If the resulting value remains positive it saves the partial remainder and writes a '1' to the quotient, otherwise it does not subtract and it writes a '0'. It was decided to attempt improving the divider by implementing it as a higher radix divider as described by chapter 14 of the book Computer Arithmetic: Algorithms and Hardware Designs by B. Parhami \cite{parhami}. Upgrading to a radix-4 divider should already provide a speed-up of 2x as 2 bits of the quotient are now calculated in the same cycle.

In order to accomplish calculating 2 bits per cycle the divisor ($d$) multiples $2d$ and $3d$ had to be pre-calculated. For $3d$ this required an adder, $2d$ is just a left shift of the divisor. Every cycle, the divisor and its multiples are shifted 2 bits to the right and subtracted from the dividend. Writing "11", "10" or "01" to the quotient if the $3d$, $2d$ or $1d$ subtraction leaves a positive partial remainder respectively. It then saves the partial remainder. If none of the subtractions leaves a positive partial remainder "00" is written to the quotient.

This implementation succeeds at reducing the division from 32 cycles to 16 cycles, reducing the total execution time of all the benchmarks with 117 million cycles. Unfortunately the extra adders necessary for subtractions and pre-calculating the divisor multiples add a significant amount of area to the processor. With the $A_{CLB}$ as defined in \cref{sec:baseperf} increasing by 115. Because of the significant increase in area and relatively limited decrease in cycles, implementing even higher radix dividers such as radix-8 was deemed undesirable.

\end{document}