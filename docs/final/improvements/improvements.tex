%!TEX root=../final.tex
%!TEX program = xelatex
%!TEX spellcheck = en_GB
\documentclass[final]{article}
\input{../../.library/preamble.tex}
\input{../../.library/style.tex}
\addbibresource{../../.library/bibliography.bib}
\begin{document}
\section{Improvements}
Many improvements of the processor were attempted. Unfortunately, because of the difficulty of changing the architecture, not all of these attempts succeeded. This section discusses the failed attempts and why they failed, and the successful attempts and their merit.
\subsection{Cache}
\subsection{Pipeline}

\subsection{Branching}
As discussed in \cref{sec:benchprof}, there is room for improvement in the area of branching. In the original implementation of the processor there are four steps/cycles in the branching process:
\begin{enumerate}
\item The memory control presents the branch opcode it fetched
\item Control decodes the opcode and passes the relevant paramaters to bus\_mux who evaluates whether the branch is taken. Meanwhile, the buffer instruction appears at the output of memory control
\item The ALU computes the new PC while the pipeline is paused
\item Memory control fetches the correct instruction while the buffer instruction enters the decode stage
\end{enumerate}
In this process, the buffer instruction refers to an instruction that is executed whether the branch is taken or not. Sometimes the compiler orders the instruction in such a way that this is a useful instruction. If the compiler is unable to find a suitable instruction, a NOP is inserted. Two main weak points are identified:
\begin{enumerate}
\item A cycle is wasted if the buffer instruction is a NOP
\item The pipeline needs to pause for a cycle to calculate the PC
\end{enumerate}
The first point turned out to be hard to improve upon. The first plan of removing all delay slots and forcing the opcode to NOP if a branch was taken as a cheap branch not taken prediction quickly fell flat as the compiler often used the buffer slot for useful instructions that should be executed whether the branch is taken or not. The second point was investigated more thoroughly.

The 

\subsection{Multiplier}
The original multiplier implementation needs 32 cycles to compute the multiplication of two 32 bits input operands. It should be noted that during this operation, the pipeline is stalled. This is not a very efficient in respect to the average amount of Instructions Per Cycle (IPC). The results of the dynamic profiling (see \cref{fig:instruction-count}) show that that multiplication (\texttt{MULT} and \texttt{MULTU}) is used quite often. To improve performance, the goal is set to design a new multiplier that can do the multiplcation in only 1 clock cycle. By using this approach, the pipeline does not have to be stalled when doing multiplication.

There are different approaches for implementing a multiplication algorithm. In general, the options are: basic, high-radix, tree and array multiplication. The original design uses a basic multiplier. This works by having two input registers for the 32 bit operands and one 64 bit output register. Each clock cycle a partial product is calculated, shifted left (depending on the weight) and added to the current value stored in the output register. For executing one multiplication, this sequence has to be repeated 32 times. In therms of area, this is very efficient. However, its performance could be better.

To speed up the computation, the original implementation is replaced by a tree multiplier. Of course, a radix type multiplier would also make the multiplier faster, but it is more suited for a balanced design (optimal cycles/area). The goal here is to get the best performance possible. A full CSA tree multiplier requires a large amount of area, but will give the fastest design. For designing a full CSA tree multiplier two methods exist: Wallace and Dadda trees. According to Townsend \cite{townsend}, the Dadda tree is slightly faster in general. So the new multiplier will be a Dadda tree multiplier.

Designing a Dadda by hand is reasonable for up to two 8-bit operands. To design a 32-bit multiplier, another method should be used. Instead, a Python script was written to build the Dadda tree. The scripts constructs the tree, reduces it using the Dadda algorithm and generates a list of full/half adders and sum/carry signals. The resulting netlist can be mapped to VHDL using a template. The script can be configured to use input operands of any bit size. The reason for doing so is simple: by setting the script to generate a VHDL description of an 8-bit multiplier, its results could still be checked by inspection. If this description is determined valid, scaling it up to 32 bits is done by changing a single line of code. After generating the Dadda tree, a VHDL testbench was written to verify the logic of the new multiplier.

For the multiplier to work on a frequency of 40 MHz, its critical path has an upper bound of 25 ns. Setting the frequency higher will make the upper bound smaller. The multiplier delay will depend on how the Xilinx place \& route tools will map the adder logic to the FPGA. If the critical path will violate the upper bound, some effort should be put in optimizing it. For example, Ramkumar \cite{ramkumar} proposes that by splitting the Dadda tree into two parts and replacing the Ripple Carry Adder (RCA), a delay reduction of 20.4\% can be achieved for a 32-bit multiplier. In this solution the RCA is replaced by a two RCAs with half the depth (one for each partial tree) and a small third RCA for summing the overlapping parts of the previous calculation. Finally, the result is computed by propagating the carry of the third RCA using a Multiplexer with Binary to Excess-1 Converter (MBEC).

To deal with signed and unsigned numbers, the Dadda tree was modified to support both operations based on an input flag. When the flag asserts (whichs means that the multiplcation will be signed), the partial products are generated according to the modified Baugh-Wooley method. If $N$ is the number of partial products ($N=32$ here), it means that the first $N-1$ partial products have their MSB inverted and the last partial product has all bits inverted except for its MSB. Also, the first and last partial product receive an extra carry. The whole modification requires just a few adders. Chapter 11 of Parhami \cite{parhami} explains this operation in more detail.

\subsection{Divider}
%Size = FIFO=14 Slice = 4623
%Size without: FIFO = 14 Slice = 4163
\Cref{fig:instruction-count} shows that very few of the instructions executed in the benchmarks are divisions. This fact initially discouraged attempting to improve the divider. However, after multiple attempts at improving the processor in other areas proved to be unfruitful it was decided to take a second look at the divider anyway. While a small percentage of the instructions are divisions, one single division still takes 32 cycles making the impact on the performance of the processor more significant than \cref{fig:instruction-count} may suggest. 

The original implementation of the division algorithm in the processor is a very simple shift and subtract algorithm. It shifts the divisor to the right attempting to subtract it from the dividend along the way. If the resulting value remains positive it saves the partial remainder and writes a '1' to the quotient, otherwise it does not subtract and it writes a '0'. It was decided to attempt improving the divider by implementing it as a higher radix divider as described by chapter 14 of the book Computer Arithmetic: Algorithms and Hardware Designs by B. Parhami \cite{parhami}. Upgrading to a radix-4 divider should already provide a speed-up of 2x as 2 bits of the quotient are now calculated in the same cycle.

In order to accomplish calculating 2 bits per cycle the divisor ($d$) multiples $2d$ and $3d$ had to be pre-calculated. For $3d$ this required an adder, $2d$ is just a left shift of the divisor. Every cycle, the divisor and its multiples are shifted 2 bits to the right and subtracted from the dividend. Writing "11", "10" or "01" to the quotient if the $3d$, $2d$ or $1d$ subtraction leaves a positive partial remainder respectively. It then saves the partial remainder. If none of the subtractions leaves a positive partial remainder "00" is written to the quotient.

This implementation succeeds at reducing the division from 32 cycles to 16 cycles, reducing the total execution time of all the benchmarks with 117 million cycles. Unfortunately the extra adders necessary for subtractions and pre-calculating the divisor multiples add a significant amount of area to the processor. With the $A_{CLB}$ as defined in \cref{sec:baseperf} increasing by 115. Because of the significant increase in area and relatively limited decrease in cycles, implementing even higher radix dividers such as radix-8 was deemed undesirable.


\end{document}